(window.webpackJsonp=window.webpackJsonp||[]).push([[631],{2881:function(e){e.exports=JSON.parse('{"bagging-description":"Die Bootstrap-Aggregation wird h\xe4ufig mit Entscheidungsbaummethoden verwendet. Dabei werden Bootstrap-Stichproben aus den urspr\xfcnglichen Trainingsdaten gezogen und ein Modell f\xfcr jede gezogene Stichprobe gesch\xe4tzt. Die Vorhersagen dieser Modelle werden dann gemittelt, um Vorhersagen mit geringerer Varianz zu erhalten, die nicht so anf\xe4llig f\xfcr \xdcberanpassungen sind.","boosting-description":"Boosting-Algorithmen wie AdaBoost lernen iterativ schwache Klassifikatoren und f\xfcgen sie durch Gewichtung zu einem endg\xfcltigen starken Klassifikator hinzu. Beim Hinzuf\xfcgen von Klassifikatoren erhalten falsch klassifizierte Eingabedaten ein h\xf6heres Gewicht und Beispiele, die richtig klassifiziert wurden, verlieren an Gewicht. So konzentrieren sich zuk\xfcnftige schwache Lerner mehr auf die Beispiele, die vorherige schwache Lerner falsch klassifiziert haben.","cart-description":"Die Klassifizierungs- und Regressionsbaumanalyse (CART) baut einen Baum auf, der von den Merkmalen einer Beobachtung (in den Zweigen dargestellt) zu einem vorhergesagten Wert (in den Bl\xe4ttern dargestellt) f\xfchrt.","classification":"Klassifizierung","clustering":"Clustering","dimensionality-reduction":"Dimensionalit\xe4tsreduktion","elastic-net-description":"Das elastische Netz ist eine regularisierte Regressionsmethode, die die L1- und L2-Penalties der Lasso- und Ridge-Methode linear kombiniert.","ensemble":"Ensemble","kmeans-description":"Gruppieren Sie die Beobachtungen in eine feste Anzahl (k) von Clustern, so dass die Mitglieder eines Clusters einander \xe4hnlicher sind als die Beobachtungen in anderen Clustern.","knn-description":"Wird sowohl f\xfcr die Regression als auch f\xfcr die Klassifizierung verwendet. Verwendet die Mehrheitsabstimmung unter den k-n\xe4chsten Punkten f\xfcr die kNN-Klassifizierung. Bei der Regression ist die Ausgabe der Durchschnitt der k-n\xe4chsten Werte.","lasso-description":"Regularisierte Regressionsmethode, die Regressionskoeffizienten mithilfe der L1-Norm bestraft. Tauscht geringere Varianz gegen ein wenig Verzerrung. F\xfchrt zu einem sp\xe4rlichen Modell.","linear-regression-description":"Modelliert die Beziehung zwischen einer skalaren Antwort und einer oder mehreren erkl\xe4renden Variablen. Die einfache lineare Regression bezieht sich auf den Fall, dass ein Pr\xe4diktor vorhanden ist, die multiple lineare Regression wird mit mehreren erkl\xe4renden Variablen verwendet. Sie wird linear genannt, weil die gesch\xe4tzte Funktion in ihren Koeffizienten linear ist.","logistic-regression-description":"Die logistische Regression ist eine Klassifizierungsmethode, die verwendet wird, um Beobachtungen einer von zwei Klassen zuzuordnen. Die logistische Regression verwendet die logistische Sigmoid-Funktion, um einen Wahrscheinlichkeitswert f\xfcr jede Klasse zur\xfcckzugeben","naive-bayes-description":"Naive Bayes-Methoden sind eine Reihe von Klassifizierungsalgorithmen, die auf der Anwendung des Bayes-Theorems mit der \\"naiven\\" Annahme der bedingten Unabh\xe4ngigkeit zwischen jedem Merkmalspaar bei gegebenem Wert der Klassenvariablen basieren.","neural-networks-description":"K\xfcnstliche neuronale Netze werden verwendet, um komplexe Beziehungen zwischen Eing\xe4ngen und Ausg\xe4ngen zu modellieren, indem eine nichtlineare Funktion ohne manuelles Feature Engineering gelernt wird.","random-forest-description":"Random Forests konstruieren zur Trainingszeit eine Vielzahl von Entscheidungsb\xe4umen und geben die Klasse zur\xfcck, die den Modus der Klassen (Klassifikation) oder die mittlere Vorhersage (Regression) der einzelnen B\xe4ume darstellt.","regression":"Regression","ridge-description":"Regularisierte Regressionsmethode, die Regressionskoeffizienten mithilfe der L2-Norm bestraft. Tauscht geringere Varianz gegen ein wenig Verzerrung. Ergibt kein sp\xe4rliches Modell, d. h. die Koeffizienten werden nicht auf Null gesetzt.","svm-description":"Support-Vektor-Maschinen sind diskriminative Klassifikatoren. Bei gelabelten Trainingsdaten findet der Algorithmus eine optimale Hyperebene, um neue Beispiele zu kategorisieren. In zwei Dimensionen ist diese Hyperebene eine Linie, die sie in zwei Teile teilt.","\xfcca-description":"Die Hauptkomponentenanalyse (PCA) verwendet eine orthogonale Transformation, um m\xf6glicherweise korrelierte Variablen in eine Menge von Werten linear unkorrelierter Variablen umzuwandeln, die Hauptkomponenten genannt werden."}')}}]);