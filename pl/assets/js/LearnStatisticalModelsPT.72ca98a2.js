(window.webpackJsonp=window.webpackJsonp||[]).push([[640],{3578:function(a){a.exports=JSON.parse('{"bagging-description":"A agrega\xe7\xe3o do bootstrap \xe9 freq\xfcentemente usada com m\xe9todos de \xe1rvore de decis\xe3o. Ao extrair amostras de bootstrap a partir dos dados originais de treinamento estimando um modelo para cada amostra retirada, as previs\xf5es de tais modelos s\xe3o ent\xe3o calculadas como m\xe9dia para produzir previs\xf5es de menor varia\xe7\xe3o n\xe3o t\xe3o propensas a sobreajustes.","boosting-description":"Algoritmos de refor\xe7o como o AdaBoost iterativamente aprendem classificadores fracos e os adicionam a um classificador final forte, pesando-os. \xc0 medida que os classificadores s\xe3o adicionados, os dados de entrada mal classificados ganham um peso maior e os exemplos que s\xe3o classificados corretamente perdem peso. Assim, os futuros alunos fracos se concentram mais nos exemplos que os alunos fracos anteriores classificaram erroneamente.","cart-description":"A an\xe1lise da \xe1rvore de classifica\xe7\xe3o e regress\xe3o (CART) constr\xf3i uma \xe1rvore que vai das caracter\xedsticas de uma observa\xe7\xe3o (representada nos galhos) a um valor previsto (representado nas folhas).","classification":"Classifica\xe7\xe3o","clustering":"Clustering","dimensionality-reduction":"Redu\xe7\xe3o da dimensionalidade","elastic-net-description":"A rede el\xe1stica \xe9 um m\xe9todo de regress\xe3o regularizada que combina linearmente as penalidades L1 e L2 dos m\xe9todos la\xe7o e cumeeira.","ensemble":"Ensemble","kmeans-description":"Agrupar observa\xe7\xf5es em um n\xfamero fixo (k) de agrupamentos de forma que os membros do agrupamento sejam mais semelhantes uns aos outros do que as observa\xe7\xf5es em outros agrupamentos.","knn-description":"Utilizado tanto para a regress\xe3o quanto para a classifica\xe7\xe3o. Utiliza o voto majorit\xe1rio entre os pontos k-nearest para a classifica\xe7\xe3o kNN. Para a regress\xe3o, o resultado \xe9 a m\xe9dia dos valores k-nearest.","lasso-description":"M\xe9todo de regress\xe3o regularizada que penaliza os coeficientes de regress\xe3o usando a norma L1. Comercializa uma varia\xe7\xe3o menor para um pouco de vi\xe9s. Conduz a um modelo esparso.","linear-regression-description":"Modela a rela\xe7\xe3o entre uma resposta escalar e uma ou mais vari\xe1veis explicativas. A regress\xe3o linear simples refere-se ao caso em que um preditor est\xe1 presente, a regress\xe3o linear m\xfaltipla \xe9 usada com m\xfaltiplas vari\xe1veis explicativas. \xc9 chamada linear porque a fun\xe7\xe3o estimada \xe9 linear em seus coeficientes.","logistic-regression-description":"A regress\xe3o log\xedstica \xe9 um m\xe9todo de classifica\xe7\xe3o utilizado para atribuir observa\xe7\xf5es a uma de duas classes. A regress\xe3o log\xedstica usa a fun\xe7\xe3o sigm\xf3ide log\xedstica para retornar um valor de probabilidade para cada classe.","naive-bayes-description":"Os m\xe9todos Bayes ing\xeanuos s\xe3o um conjunto de algoritmos de classifica\xe7\xe3o baseados na aplica\xe7\xe3o do teorema de Bayes com a suposi\xe7\xe3o \\"ing\xeanua\\" de independ\xeancia condicional entre cada par de caracter\xedsticas dado o valor da vari\xe1vel de classe.","neural-networks-description":"As redes neurais artificiais s\xe3o usadas para modelar rela\xe7\xf5es complexas entre entradas e sa\xeddas, aprendendo uma fun\xe7\xe3o n\xe3o linear sem engenharia manual de caracter\xedsticas.","random-forest-description":"As Florestas Aleat\xf3rias constroem uma multid\xe3o de \xe1rvores de decis\xe3o em tempo de treinamento e retornam a classe que \xe9 o modo das classes (classifica\xe7\xe3o) ou previs\xe3o m\xe9dia (regress\xe3o) das \xe1rvores individuais.","regression":"Regress\xe3o","ridge-description":"M\xe9todo de regress\xe3o regularizada que penaliza os coeficientes de regress\xe3o usando a norma L2. Comercializa uma varia\xe7\xe3o menor para um pouco de vi\xe9s. N\xe3o produz um modelo esparso, ou seja, os coeficientes n\xe3o s\xe3o levados a zero.","svm-description":"As m\xe1quinas Vector de apoio s\xe3o classificadoras discriminat\xf3rias. Dados os dados de treinamento rotulados, o algoritmo encontra um hiperplano ideal para categorizar novos exemplos. Em duas dimens\xf5es, este hiperplano \xe9 uma linha que o divide em duas partes.","\xfcca-description":"A An\xe1lise de Componentes Principais (PCA) usa uma transforma\xe7\xe3o ortogonal para converter vari\xe1veis possivelmente correlacionadas em um conjunto de valores de vari\xe1veis linearmente n\xe3o correlacionadas chamadas componentes principais."}')}}]);