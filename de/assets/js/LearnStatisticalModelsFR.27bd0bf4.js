(window.webpackJsonp=window.webpackJsonp||[]).push([[647],{3186:function(e){e.exports=JSON.parse('{"bagging-description":"L\'agr\xe9gation bootstrap est souvent utilis\xe9e avec les m\xe9thodes d\'arbre de d\xe9cision. En tirant des \xe9chantillons bootstrap des donn\xe9es de formation originales, en estimant un mod\xe8le pour chaque \xe9chantillon tir\xe9, les pr\xe9dictions desdits mod\xe8les sont ensuite moyenn\xe9es pour donner des pr\xe9dictions \xe0 faible variance moins sujettes au surajustement.","boosting-description":"Les algorithmes de boosting tels qu\'AdaBoost apprennent it\xe9rativement les classificateurs faibles et les ajoutent \xe0 un classificateur fort final en les pond\xe9rant. \xc0 mesure que des classificateurs sont ajout\xe9s, les donn\xe9es d\'entr\xe9e mal class\xe9es prennent plus de poids et les exemples qui sont class\xe9s correctement perdent du poids. Ainsi, les futurs apprenants faibles se concentrent davantage sur les exemples que les apprenants faibles pr\xe9c\xe9dents ont mal class\xe9s.","cart-description":"L\'analyse CART (Classification And Regression Tree) construit un arbre qui va des caract\xe9ristiques d\'une observation (repr\xe9sent\xe9es dans les branches) \xe0 une valeur pr\xe9dite (repr\xe9sent\xe9e dans les feuilles).","classification":"Classification","clustering":"Regroupement","dimensionality-reduction":"R\xe9duction de la dimensionnalit\xe9","elastic-net-description":"Le filet \xe9lastique est une m\xe9thode de r\xe9gression r\xe9gularis\xe9e qui combine lin\xe9airement les p\xe9nalit\xe9s L1 et L2 des m\xe9thodes du lasso et des cr\xeates.","ensemble":"Ensemble","kmeans-description":"Regrouper les observations en un nombre fixe (k) de groupes de mani\xe8re \xe0 ce que les membres des groupes soient plus semblables les uns aux autres qu\'aux observations dans d\'autres groupes.","knn-description":"Utilis\xe9 \xe0 la fois pour la r\xe9gression et la classification. Utilise le vote majoritaire parmi les points k les plus proches pour la classification kNN. Pour la r\xe9gression, le r\xe9sultat est la moyenne des valeurs k les plus proches.","lasso-description":"M\xe9thode de r\xe9gression r\xe9gularis\xe9e qui p\xe9nalise les coefficients de r\xe9gression en utilisant la norme L1. Traite une variance plus faible pour un peu de biais. Conduit \xe0 un mod\xe8le \xe9pars.","linear-regression-description":"Mod\xe9lisation de la relation entre une r\xe9ponse scalaire et une ou plusieurs variables explicatives. La r\xe9gression lin\xe9aire simple fait r\xe9f\xe9rence au cas o\xf9 un pr\xe9dicteur est pr\xe9sent, la r\xe9gression lin\xe9aire multiple est utilis\xe9e avec de multiples variables explicatives. Elle est appel\xe9e lin\xe9aire parce que la fonction estim\xe9e est lin\xe9aire dans ses coefficients.","logistic-regression-description":"La r\xe9gression logistique est une m\xe9thode de classification utilis\xe9e pour attribuer des observations \xe0 l\'une ou l\'autre des deux classes. La r\xe9gression logistique utilise la fonction sigmo\xefde logistique pour renvoyer une valeur de probabilit\xe9 pour chaque classe","naive-bayes-description":"Les m\xe9thodes na\xefves de Bayes sont un ensemble d\'algorithmes de classification bas\xe9s sur l\'application du th\xe9or\xe8me de Bayes avec l\'hypoth\xe8se \\"na\xefve\\" d\'ind\xe9pendance conditionnelle entre chaque paire de caract\xe9ristiques \xe9tant donn\xe9 la valeur de la variable de classe.","neural-networks-description":"Les r\xe9seaux neuronaux artificiels sont utilis\xe9s pour mod\xe9liser des relations complexes entre les entr\xe9es et les sorties en apprenant une fonction non lin\xe9aire sans ing\xe9nierie manuelle des caract\xe9ristiques.","random-forest-description":"Random Forests construit une multitude d\'arbres de d\xe9cision au moment de l\'entra\xeenement et retourne la classe qui est le mode des classes (classification) ou la pr\xe9diction moyenne (r\xe9gression) des arbres individuels.","regression":"R\xe9gression","ridge-description":"M\xe9thode de r\xe9gression r\xe9gularis\xe9e qui p\xe9nalise les coefficients de r\xe9gression en utilisant la norme L2. Elle n\xe9gocie une variance plus faible pour un peu de biais. Ne produit pas un mod\xe8le peu dense, c\'est-\xe0-dire que les coefficients ne sont pas ramen\xe9s \xe0 z\xe9ro.","svm-description":"Les machines \xe0 vecteurs de soutien sont des classificateurs discriminants. \xc0 partir de donn\xe9es d\'entra\xeenement \xe9tiquet\xe9es, l\'algorithme trouve un hyperplan optimal pour cat\xe9goriser de nouveaux exemples. En deux dimensions, cet hyperplan est une ligne qui le divise en deux parties.","\xfcca-description":"L\'analyse en composantes principales (ACP) utilise une transformation orthogonale pour convertir des variables \xe9ventuellement corr\xe9l\xe9es en un ensemble de valeurs de variables lin\xe9airement non corr\xe9l\xe9es appel\xe9es composantes principales."}')}}]);