(window.webpackJsonp=window.webpackJsonp||[]).push([[636],{2960:function(e){e.exports=JSON.parse('{"bagging-description":"Bootstrap aggregating is often used with decision tree methods. Drawing bootstrap samples from the original training data estimating a model for each drawn sample, the predictions of said models are then averaged to yield lower-variance predictions not as prone to overfitting.","boosting-description":"Boosting algorithms such as AdaBoost iteratively learn weak classifiers and add them to a final strong classifier by weighting them. As classifiers are added, misclassified input data gain a higher weight and examples that are classified correctly lose weight. Thus, future weak learners focus more on the examples that previous weak learners misclassified.","cart-description":"Classification And Regression Tree (CART) analysis builds a tree that goes from the features of an observation (represented in the branches) to a predicted value (represented in the leaves).","classification":"Classification","clustering":"Clustering","dimensionality-reduction":"Dimensionality Reduction","elastic-net-description":"Elastic net is a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods.","ensemble":"Ensemble","kmeans-description":"Group observations into a fixed number (k) of clusters such that cluster members are more similar to each other than to observations in other clusters.","knn-description":"Used for both regression and classification. Uses majority vote among k-nearest points for kNN classification. For regression, the output is the average of the k-nearest values.","lasso-description":"Regularized regression method that penalizes regression coefficients using the L1 norm. Trades lower variance for a bit of bias. Leads to a sparse model.","linear-regression-description":"Models the relationship between a scalar response and one or more explanatory variables. Simple linear regression refers to the case where one predictor is present, multiple linear regression is used with multiple explanatory variables. It is called linear because the estimated function is linear in its coefficients.","logistic-regression-description":"Logistic regression is a classification method used to assign observations to either of two classes. Logistic regression uses the logistic sigmoid function to return a probability value for each class","naive-bayes-description":"Naive Bayes methods are a set of classification algorithms based on applying Bayes\u2019 theorem with the \u201cnaive\u201d assumption of conditional independence between every pair of features given the value of the class variable.","neural-networks-description":"Artificial neural networks are  used to model complex relationships between inputs and outputs by learning a non-linear function without manual feature engineering.","random-forest-description":"Random Forests construct a multitude of decision trees at training time and return the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.","regression":"Regression","ridge-description":"Regularized regression method that penalizes regression coefficients using the L2 norm. Trades lower variance for a bit of bias. Does not yield a sparse model, i.e. coefficients are not driven to zero.","svm-description":"Support Vector Machines are discriminative classifiers. Given labeled training data, the algorithm finds an optimal hyperplane to categorize new examples. In two dimensions this hyperplane is a line dividing it into two parts.","\xfcca-description":"Principal Component Analysis (PCA) uses an orthogonal transformation to convert possibly correlated variables into a set of values of linearly uncorrelated variables called principal components."}')}}]);