(window.webpackJsonp=window.webpackJsonp||[]).push([[656],{3014:function(e){e.exports=JSON.parse('{"bagging-description":"La agregaci\xf3n por medio de un \xe1rbol de decisi\xf3n se utiliza a menudo. Al extraer muestras de bootstrap de los datos originales de capacitaci\xf3n, estimando un modelo para cada muestra extra\xedda, las predicciones de dichos modelos se promedian para obtener predicciones de menor varianza y no tan propensas a la sobrecarga.","boosting-description":"Los algoritmos de potenciaci\xf3n como el AdaBoost aprenden iterativamente los clasificadores d\xe9biles y los a\xf1aden a un clasificador fuerte final mediante su ponderaci\xf3n. A medida que se a\xf1aden los clasificadores, los datos de entrada mal clasificados ganan m\xe1s peso y los ejemplos que se clasifican correctamente pierden peso. As\xed, los futuros alumnos d\xe9biles se centran m\xe1s en los ejemplos que los anteriores alumnos d\xe9biles clasificaron incorrectamente.","cart-description":"El an\xe1lisis del \xc1rbol de Clasificaci\xf3n y Regresi\xf3n (CART) construye un \xe1rbol que va desde las caracter\xedsticas de una observaci\xf3n (representadas en las ramas) hasta un valor predicho (representado en las hojas).","classification":"Clasificaci\xf3n","clustering":"Agrupaci\xf3n","dimensionality-reduction":"Reducci\xf3n de la dimensionalidad","elastic-net-description":"La red el\xe1stica es un m\xe9todo de regresi\xf3n regularizado que combina linealmente las penalizaciones L1 y L2 de los m\xe9todos de lazo y cresta.","ensemble":"Conjunto","kmeans-description":"Agrupar las observaciones en un n\xfamero fijo (k) de c\xfamulos, de manera que los miembros del c\xfamulo sean m\xe1s similares entre s\xed que a las observaciones en otros c\xfamulos.","knn-description":"Se utiliza tanto para la regresi\xf3n como para la clasificaci\xf3n. Utiliza el voto mayoritario entre los puntos m\xe1s cercanos para la clasificaci\xf3n kNN. Para la regresi\xf3n, el resultado es el promedio de los valores m\xe1s cercanos.","lasso-description":"M\xe9todo de regresi\xf3n regularizada que penaliza los coeficientes de regresi\xf3n usando la norma L1. Reduce la varianza por un poco de sesgo. Conduce a un modelo disperso.","linear-regression-description":"Modela la relaci\xf3n entre una respuesta escalar y una o m\xe1s variables explicativas. La regresi\xf3n lineal simple se refiere al caso en que hay un predictor presente, la regresi\xf3n lineal m\xfaltiple se utiliza con m\xfaltiples variables explicativas. Se denomina lineal porque la funci\xf3n estimada es lineal en sus coeficientes.","logistic-regression-description":"La regresi\xf3n log\xedstica es un m\xe9todo de clasificaci\xf3n utilizado para asignar observaciones a cualquiera de las dos clases. La regresi\xf3n log\xedstica utiliza la funci\xf3n sigmoide log\xedstica para devolver un valor de probabilidad para cada clase","naive-bayes-description":"Los m\xe9todos ingenuos de Bayes son un conjunto de algoritmos de clasificaci\xf3n basados en la aplicaci\xf3n del teorema de Bayes con el supuesto \\"ingenuo\\" de independencia condicional entre cada par de caracter\xedsticas dado el valor de la variable de clase.","neural-networks-description":"Las redes neuronales artificiales se utilizan para modelar relaciones complejas entre entradas y salidas mediante el aprendizaje de una funci\xf3n no lineal sin ingenier\xeda de caracter\xedsticas manuales.","random-forest-description":"Los bosques aleatorios construyen una multitud de \xe1rboles de decisi\xf3n en el momento de la formaci\xf3n y devuelven la clase que es el modo de las clases (clasificaci\xf3n) o la predicci\xf3n media (regresi\xf3n) de los \xe1rboles individuales.","regression":"Regresi\xf3n","ridge-description":"M\xe9todo de regresi\xf3n regularizada que penaliza los coeficientes de regresi\xf3n usando la norma L2. Reduce la varianza por un poco de sesgo. No da un modelo disperso, es decir, los coeficientes no se llevan a cero.","svm-description":"Las M\xe1quinas Vectoriales de Apoyo son clasificadores discriminatorios. Dados los datos de entrenamiento etiquetados, el algoritmo encuentra un hiperplano \xf3ptimo para categorizar nuevos ejemplos. En dos dimensiones este hiperplano es una l\xednea que lo divide en dos partes.","\xfcca-description":"El an\xe1lisis de componentes principales (PCA) utiliza una transformaci\xf3n ortogonal para convertir las variables posiblemente correlacionadas en un conjunto de valores de variables linealmente no correlacionadas llamadas componentes principales."}')}}]);